<img id="videoC" name="videoC" width="640" height="360" hspace="0" vspace="0" src="http://192.168.1.111:81/videostream.cgi?user=admin&amp;pwd=888888" style="width: 640px; height: 360px;">


<img id="videoC" name="videoC" width="640" height="360" hspace="0" vspace="0" src="http://192.168.1.111:81/videostream.cgi?user=admin&amp;pwd=888888" style="width: 640px; height: 360px;">


face_cascade = cv2.CascadeClassifier("image/haarcascade_frontalface_default.xml")

while (cap.isOpened()):
    check , frame = cap.read()
    if check == True :
        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
        fact_detect = face_cascade.detectMultiScale(gray,1.2,5)
        
        for (x,y,w,h)in fact_detect:
            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,169,0),thickness=5)
            cv2.imshow("Output",frame)

        if cv2.waitKey(1) & 0XFF == ord ("e"):
            break
    
    cap.release()
    cv2.destroyAllWindows()

'http://192.168.1.111:81/decoder_control.cgi?loginuse=admin&loginpas=888888&command=0&onestep=0&16578693944670.8208924423233741&_=1657869394468' #up
cv2.putText(frame, f"Range M.",(x,y-4),cv2.FONT_HERSHEY_SIMPLEX,0.8,gray,2)

=====================================================================================================================================================
import cv2 
import urllib.request
cap = cv2.VideoCapture('http://192.168.1.111:81/videostream.cgi?user=admin&pwd=888888')
urlup = 'http://192.168.1.111:81/decoder_control.cgi?loginuse=admin&loginpas=888888&command=0&onestep=0&16578694035210.14075174081563602&_=1657869403521'
urldown ='http://192.168.1.111:81/decoder_control.cgi?loginuse=admin&loginpas=888888&command=2&onestep=0&16578736569330.9931775446378299&_=1657873656933'
urlstop = 'http://192.168.1.111:81/decoder_control.cgi?loginuse=admin&loginpas=888888&command=1&onestep=0&16578739198270.508296404339176&_=1657873919827'
urlleft = 'http://192.168.1.111:81/decoder_control.cgi?loginuse=admin&loginpas=888888&command=6&onestep=0&16578746641180.49536594814961243&_=1657874664118'
urlright = 'http://192.168.1.111:81/decoder_control.cgi?loginuse=admin&loginpas=888888&command=5&onestep=0&16578751799960.7458317937009731&_=1657875179996'
face_detector = cv2.CascadeClassifier("image/haarcascade_frontalface_default.xml")
while (True):
   check , frame = cap.read()   
   gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
   faces = face_detector.detectMultiScale(gray,1.3,5)
   for (x,y,w,h) in faces:
       
       cv2.rectangle(frame,(x,y),(x+w,y+h),(102,255,178),2)
   cv2.imshow("CCTVCap",frame)
   key = cv2.waitKey(1) & 0xFF   
   if key == ord('w'):
      urllib.request.urlopen(urlup)
   if key == ord('s'):
      urllib.request.urlopen(urldown)
   if key == ord('r'):
      urllib.request.urlopen(urlstop)
   if key == ord('a'):
      urllib.request.urlopen(urlleft) 
   if key == ord('d'):
      urllib.request.urlopen(urlleft)

=====================================================================================================================================================


import cv2 
import urllib.request
cap = cv2.VideoCapture('http://192.168.1.111:81/videostream.cgi?user=admin&pwd=888888')
urlup = 'http://192.168.1.111:81/decoder_control.cgi?loginuse=admin&loginpas=888888&command=0&onestep=0&16578694035210.14075174081563602&_=1657869403521'
urldown ='http://192.168.1.111:81/decoder_control.cgi?loginuse=admin&loginpas=888888&command=2&onestep=0&16578736569330.9931775446378299&_=1657873656933'
urlstop = 'http://192.168.1.111:81/decoder_control.cgi?loginuse=admin&loginpas=888888&command=1&onestep=0&16578739198270.508296404339176&_=1657873919827'
urlleft = 'http://192.168.1.111:81/decoder_control.cgi?loginuse=admin&loginpas=888888&command=6&onestep=0&16578746641180.49536594814961243&_=1657874664118'
urlright = 'http://192.168.1.111:81/decoder_control.cgi?loginuse=admin&loginpas=888888&command=5&onestep=0&16578751799960.7458317937009731&_=1657875179996'
face_detector = cv2.CascadeClassifier("image/haarcascade_frontalface_default.xml")
face_locations = []
face_encodings = []
face_names = []
face_percent = []
while (True):
   check , frame = cap.read()   
   for (top,right,bottom, left), name, percent, in zip(face_locations, face_names, face_percent):   
            top*= 2
            right*= 2
            bottom*= 2
            left*= 2

            if name == "UNKNOWN":
                color = [46,2,209]
            else:
                color = [255,102,51]

            cv2.rectangle(frame, (left,top), (right,bottom), color, 2)
            cv2.rectangle(frame, (left-1, top -30), (right+1,top), color, cv2.FILLED)
            cv2.rectangle(frame, (left-1, bottom), (right+1,bottom+30), color, cv2.FILLED)
            font = cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(frame, name, (left+6, top-6), font, 0.6, (255,255,255), 1)
            cv2.putText(frame, "MATCH: "+str(percent)+"%", (left+6, bottom+23), font, 0.6, (255,255,255), 1)
   cv2.imshow("CCTVCap",frame)
   key = cv2.waitKey(1) & 0xFF   
   if key == ord('w'):
      urllib.request.urlopen(urlup)
   if key == ord('s'):
      urllib.request.urlopen(urldown)
   if key == ord('r'):
      urllib.request.urlopen(urlstop)
   if key == ord('a'):
      urllib.request.urlopen(urlleft) 
   if key == ord('d'):
      urllib.request.urlopen(urlleft)

=============================================================================================================================================================================

import face_recognition as face 
import numpy as np 
import cv2

#ORIGINAL_CODE_CREDIT:  https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py

#ดึงวิดีโอตัวอย่างเข้ามา, ถ้าต้องการใช้webcamให้ใส่เป็น0
video_capture = cv2.VideoCapture("sample.mp4") 

#ใบหน้าคนที่ต้องการรู้จำเป็นreference #คนที่1
pop_image = face.load_image_file("pop.jpg")
pop_face_encoding = face.face_encodings(pop_image)[0]

#ใบหน้าคนที่ต้องการรู้จำเป็นreference #คนที่2
oat_image = face.load_image_file("oat.jpg")
oat_face_encoding = face.face_encodings(oat_image)[0]

#ประกาศตัวแปร
face_locations = []
face_encodings = []
face_names = []
face_percent = []
#ตัวแปรนี้ใช้สำหรับคิดเฟรมเว้นเฟรมเพื่อเพิ่มfps 
process_this_frame = True

known_face_encodings = [pop_face_encoding, oat_face_encoding]
known_face_names = ["PONGKUL", "PRAMOTE"]

#loopคำนวณแต่ละเฟรมของวิดีโอ
while True:
    #อ่านค่าแต่ละเฟรมจากวิดีโอ
    ret, frame = video_capture.read()
    if ret:
        #ลดขนาดสองเท่าเพื่อเพิ่มfps 
        small_frame = cv2.resize(frame, (0,0), fx=0.5,fy=0.5)
        #เปลี่ยน bgrเป็น rgb 
        rgb_small_frame = small_frame[:,:,::-1]

        face_names = []
        face_percent = []

        if process_this_frame:
            #ค้นหาตำแหน่งใบหน้าในเฟรม 
            face_locations = face.face_locations(rgb_small_frame, model="cnn")
            #นำใบหน้ามาหาfeaturesต่างๆที่เป็นเอกลักษณ์ 
            face_encodings = face.face_encodings(rgb_small_frame, face_locations)
            
            #เทียบแต่ละใบหน้า
            for face_encoding in face_encodings:
                face_distances = face.face_distance(known_face_encodings, face_encoding)
                best = np.argmin(face_distances)
                face_percent_value = 1-face_distances[best]

                #กรองใบหน้าที่ความมั่นใจ50% ปล.สามารถลองเปลี่ยนได้
                if face_percent_value >= 0.5:
                    name = known_face_names[best]
                    percent = round(face_percent_value*100,2)
                    face_percent.append(percent)
                else:
                    name = "UNKNOWN"
                    face_percent.append(0)
                face_names.append(name)

        #วาดกล่องและtextเมื่อแสดงผลออกมาออกมา
        for (top,right,bottom, left), name, percent in zip(face_locations, face_names, face_percent):
            top*= 2
            right*= 2
            bottom*= 2
            left*= 2

            if name == "UNKNOWN":
                color = [46,2,209]
            else:
                color = [255,102,51]

            cv2.rectangle(frame, (left,top), (right,bottom), color, 2)
            cv2.rectangle(frame, (left-1, top -30), (right+1,top), color, cv2.FILLED)
            cv2.rectangle(frame, (left-1, bottom), (right+1,bottom+30), color, cv2.FILLED)
            font = cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(frame, name, (left+6, top-6), font, 0.6, (255,255,255), 1)
            cv2.putText(frame, "MATCH: "+str(percent)+"%", (left+6, bottom+23), font, 0.6, (255,255,255), 1)


        #สลับค่าเป็นค่าตรงข้ามเพื่อให้คิดเฟรมเว้นเฟรม
        process_this_frame = not process_this_frame

        #แสดงผลลัพท์ออกมา
        cv2.imshow("Video", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    else:
        break

#ล้างค่าต่างๆเมื่อปิดโปรแกรม
video_capture.release()
cv2.destroyAllWindows()


============================================================================================
============================================================================================
=============================================================================================

Project Open CV IP CAM 

======================
======================
part 01 
=======
=======


import cv2 
import urllib.request
cap = cv2.VideoCapture('http://192.168.1.156:40872/videostream.cgi?user=admin&pwd=888888')
urlup = 'http://192.168.1.156:40872/decoder_control.cgi?loginuse=admin&loginpas=888888&command=0&onestep=0&16665949541060.5488437026730646&_=1666594954106'
urldown ='http://192.168.1.156:40872/decoder_control.cgi?loginuse=admin&loginpas=888888&command=2&onestep=0&16665953768060.9578758702565133&_=1666595376807'
urlleft = 'http://192.168.1.156:40872/decoder_control.cgi?loginuse=admin&loginpas=888888&command=4&onestep=0&16665954389540.8104276785346785&_=1666595438954'
urlright = ' http://192.168.1.156:40872/decoder_control.cgi?loginuse=admin&loginpas=888888&command=6&onestep=0&16665954793680.14226293471168838&_=1666595479368'
urlstop = 'http://192.168.1.156:40872/decoder_control.cgi?loginuse=admin&loginpas=888888&command=5&onestep=0&16665950820350.04820711562524305&_=1666595082035'
face_detector = cv2.CascadeClassifier(cv2.data.haarcascades +"haarcascade_frontalface_default.xml")
while True:
   check,frame = cap.read()   
   gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
   faces = face_detector.detectMultiScale(gray,1.3,5)
   for (x,y,w,h) in faces:
       
       cv2.rectangle(frame,(x,y),(x+w,y+h),(102,255,178),2)
   cv2.imshow("CCTVCap",frame)

   key = cv2.waitKey(1) & 0xFF   
   if key == ord('w'):
      urllib.request.urlopen(urlup)
   if key == ord('s'):
      urllib.request.urlopen(urldown)
   if key == ord('a'):
      urllib.request.urlopen(urlleft) 
   if key == ord('d'):
      urllib.request.urlopen(urlright)
   if key == ord('r'):
      urllib.request.urlopen(urlstop)
      

*** ต้องค่อยเปลี่ยน port ทุกครั้งหลังเปิดใช้งาน ***

==============================================================================================
=======
part 02
=======
=======


import numpy as np 
import cv2 
import dlib 
import os 
import pickle 
path = "images"
detector = dlib.get_frontal_face_detector()
sp = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')
model = dlib.face_recognition_model_v1 ('dlib_face_recognition_resnet_model_v1.dat')
FACE_DESC = []
FACE_NAME = []
for fn in os.listdir (path):
    if fn.endswith ('.jpg'):
       img = cv2.imread(path + fn)[:,:,::-1] 
       dets = detector (img,1)
       for k,d in enumerate(dets):
           shape = sp (img,d)
           face_desc = model.compute_face_descriptor(img,shape,1)
           FACE_DESC.append(face_desc)
           print('loading...',fn)
           FACE_NAME.append(fn[:fn.index('_')])
pickle.dump((FACE_DESC,FACE_NAME),open('trainset.pk','wb'))

==========================================================================================
==========
==========
Part 03 
==========
==========

import numpy as np
from PIL import Image
import os
import cv2 

def train_classifier(data_dir):
    path = [os.path.join (data_dir,f) for f in os.listdir(data_dir)]

    faces = []
    ids  =  []

    for image in path:
        img=Image,open(image).convert("t")
        imageNp=np.array(img,'uint8')
        id=int(os.path.split(image)[1].split(".")[1])
        faces.append(imageNp)
        ids.append(id)

    ids = np.array(ids)
    
    clf = cv2.face.LBPHFaceRecognizer_create()
    clf.train(faces,ids)
    clf.write("classifier.xml")

train_classifier("images")

      
